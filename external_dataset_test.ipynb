{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38bc7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "from src.model_trainer import load_trained_model, get_model_predictions\n",
    "from src.data_preprocessor import TextPreprocessor, FakeNewsDataset, collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f25dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca42267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_external_df(\n",
    "        path,\n",
    "        delimiter=',',\n",
    "        text_column='text',\n",
    "        label_column='label',\n",
    "        true_label='true',\n",
    "        fake_label='false',\n",
    "        batch_size=16,\n",
    "        max_sentences=20,\n",
    "        max_words_per_sentence=50,\n",
    "):\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1.  Load the file and keep only the columns we need\n",
    "    # ------------------------------------------------------------------\n",
    "    df = pd.read_csv(path, delimiter=delimiter, usecols=[text_column, label_column])\\\n",
    "           .dropna(subset=[text_column, label_column])\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2.  Normalise the label values to the exact strings that were\n",
    "    #     used to fit the original LabelEncoder\n",
    "    # ------------------------------------------------------------------\n",
    "    mapping = {true_label: \"true\", fake_label: \"fake\"}\n",
    "    df[\"label_norm\"] = df[label_column].map(mapping)\n",
    "\n",
    "    if df[\"label_norm\"].isna().any():\n",
    "        bad_values = df.loc[df[\"label_norm\"].isna(), label_column].unique()\n",
    "        raise ValueError(f\"Unmapped label values found: {bad_values}\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3.  Load model + encoder + vocabulary\n",
    "    # ------------------------------------------------------------------\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model, _, ckpt = load_trained_model(\"best_han_model.pth\", device=device)\n",
    "    label_encoder = ckpt[\"label_encoder\"]\n",
    "\n",
    "    preproc = TextPreprocessor()\n",
    "    preproc.load_vocabulary(\"vocabulary.pkl\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4.  Build the FakeNewsDataset\n",
    "    # ------------------------------------------------------------------\n",
    "    texts  = df[text_column].tolist()\n",
    "    labels = label_encoder.transform(df[\"label_norm\"])\n",
    "\n",
    "    dataset = FakeNewsDataset(\n",
    "        texts,\n",
    "        labels,\n",
    "        preproc,\n",
    "        max_sentences,\n",
    "        max_words_per_sentence,\n",
    "    )\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=collate_fn,\n",
    "                        num_workers=2)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 5.  Run inference\n",
    "    # ------------------------------------------------------------------\n",
    "    results = get_model_predictions(model, loader, label_encoder, device)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 6.  Report metrics\n",
    "    # ------------------------------------------------------------------\n",
    "    acc = accuracy_score(results[\"true_labels\"], results[\"predictions\"])\n",
    "    report = classification_report(\n",
    "        results[\"true_labels\"], results[\"predictions\"],\n",
    "        target_names=label_encoder.classes_,\n",
    "        digits=4,\n",
    "    )\n",
    "\n",
    "    print(f\"Accuracy : {acc:.4f}\\n\")\n",
    "    print(report)\n",
    "\n",
    "    return acc, report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f220444",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/aadyasingh55/fake-news-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b0ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best_han_model.pth\n",
      "Best validation accuracy: 0.9997775800711743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convertng text to hierarchical format...: 100%|██████████| 24353/24353 [00:27<00:00, 895.03it/s]\n",
      "Getting predictions: 100%|██████████| 1523/1523 [00:15<00:00, 99.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9813\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake     0.9614    0.9992    0.9799     11107\n",
      "        true     0.9993    0.9663    0.9825     13246\n",
      "\n",
      "    accuracy                         0.9813     24353\n",
      "   macro avg     0.9803    0.9828    0.9812     24353\n",
      "weighted avg     0.9820    0.9813    0.9813     24353\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9813164702500718,\n",
       " '              precision    recall  f1-score   support\\n\\n        fake     0.9614    0.9992    0.9799     11107\\n        true     0.9993    0.9663    0.9825     13246\\n\\n    accuracy                         0.9813     24353\\n   macro avg     0.9803    0.9828    0.9812     24353\\nweighted avg     0.9820    0.9813    0.9813     24353\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"aadyasingh55/fake-news-classification\")\n",
    "evaluate_on_external_df(\n",
    "    path = path + '/train (2).csv',\n",
    "    delimiter = ';',\n",
    "    true_label = 1,\n",
    "    fake_label = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a52e45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b645fb51",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/hassanamin/textdb3?select=fake_or_real_news.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22cadb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best_han_model.pth\n",
      "Best validation accuracy: 0.9995551601423488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convertng text to hierarchical format...: 100%|██████████| 6335/6335 [00:08<00:00, 729.97it/s]\n",
      "Getting predictions: 100%|██████████| 396/396 [00:01<00:00, 242.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5165\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake     0.5082    0.9899    0.6716      3164\n",
      "        true     0.8140    0.0442    0.0838      3171\n",
      "\n",
      "    accuracy                         0.5165      6335\n",
      "   macro avg     0.6611    0.5170    0.3777      6335\n",
      "weighted avg     0.6612    0.5165    0.3774      6335\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5164956590370955,\n",
       " '              precision    recall  f1-score   support\\n\\n        fake     0.5082    0.9899    0.6716      3164\\n        true     0.8140    0.0442    0.0838      3171\\n\\n    accuracy                         0.5165      6335\\n   macro avg     0.6611    0.5170    0.3777      6335\\nweighted avg     0.6612    0.5165    0.3774      6335\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"hassanamin/textdb3\")\n",
    "evaluate_on_external_df(\n",
    "    path = path + '/fake_or_real_news.csv',\n",
    "    fake_label = 'FAKE',\n",
    "    true_label = 'REAL'    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18904e82",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification\n",
    "\n",
    "\n",
    "> There is an error in the data card of this model, labels are inverted (check discussion). Code below is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6928134a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best_han_model.pth\n",
      "Best validation accuracy: 0.9995551601423488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convertng text to hierarchical format...: 100%|██████████| 72095/72095 [01:23<00:00, 866.70it/s]\n",
      "Getting predictions: 100%|██████████| 4506/4506 [00:17<00:00, 251.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8212\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake     0.7431    0.9967    0.8514     37067\n",
      "        true     0.9945    0.6354    0.7754     35028\n",
      "\n",
      "    accuracy                         0.8212     72095\n",
      "   macro avg     0.8688    0.8161    0.8134     72095\n",
      "weighted avg     0.8653    0.8212    0.8145     72095\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8211665164019696,\n",
       " '              precision    recall  f1-score   support\\n\\n        fake     0.7431    0.9967    0.8514     37067\\n        true     0.9945    0.6354    0.7754     35028\\n\\n    accuracy                         0.8212     72095\\n   macro avg     0.8688    0.8161    0.8134     72095\\nweighted avg     0.8653    0.8212    0.8145     72095\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"saurabhshahane/fake-news-classification\")\n",
    "evaluate_on_external_df(\n",
    "    path = path + \"/WELFake_Dataset.csv\",\n",
    "    fake_label = 1,\n",
    "    true_label = 0\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
